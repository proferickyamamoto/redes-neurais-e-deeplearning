# üß† Aula 12.2 ‚Äì Segundo Semestre: Revis√£o e Introdu√ß√£o √†s Redes Convolucionais (CNNs)

## üéØ Objetivo

Retomar os principais conceitos abordados no primeiro semestre e introduzir de forma te√≥rica e pr√°tica as Redes Neurais Convolucionais (CNNs), com base em literatura cient√≠fica e aplica√ß√µes reais.

---

## üìö Parte 1 ‚Äì Revis√£o dos Fundamentos (com exemplo de ECG e EDA com TSFEL)

Durante o primeiro semestre, exploramos a base das redes neurais artificiais (RNA), abordando estruturas feedforward, algoritmos de retropropaga√ß√£o (backpropagation), fun√ß√µes de ativa√ß√£o, regulariza√ß√£o (L2, dropout, batch normalization) e otimizadores como SGD, Adam e RMSProp. A compreens√£o dessas estruturas √© essencial para avan√ßarmos para arquiteturas mais complexas. Como continuidade do exemplo de ECG, podemos implementar um pipeline de classifica√ß√£o com RNA (MLP), comparando Grid Search e Random Search, avaliando tamb√©m o tempo de infer√™ncia de cada abordagem e apresentando os relat√≥rios de desempenho.

```python
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import time

# Separar os dados
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)

# Grid Search
param_grid = {
    'hidden_layer_sizes': [(100,), (50, 50), (30, 30, 30)],
    'alpha': [0.0001, 0.01, 0.1],
    'learning_rate_init': [0.001, 0.01]
}

start_grid = time.time()
grid_search = GridSearchCV(MLPClassifier(max_iter=500), param_grid, cv=3)
grid_search.fit(X_train, y_train)
grid_time = time.time() - start_grid

# Random Search
param_dist = {
    'hidden_layer_sizes': [(100,), (50, 50), (30, 30, 30), (20, 20, 20)],
    'alpha': [0.0001, 0.001, 0.01, 0.1],
    'learning_rate_init': [0.0001, 0.001, 0.01]
}

start_rand = time.time()
rand_search = RandomizedSearchCV(MLPClassifier(max_iter=500), param_dist, n_iter=10, cv=3, random_state=42)
rand_search.fit(X_train, y_train)
rand_time = time.time() - start_rand

# Avalia√ß√£o Grid
y_pred_grid = grid_search.predict(X_test)
print("
GridSearch Classification Report:")
print(classification_report(y_test, y_pred_grid))
print("Matriz de Confus√£o (GridSearch):")
print(confusion_matrix(y_test, y_pred_grid))
print(f"Tempo de Infer√™ncia GridSearch: {grid_time:.2f} segundos")

# Avalia√ß√£o Random
y_pred_rand = rand_search.predict(X_test)
print("
RandomSearch Classification Report:")
print(classification_report(y_test, y_pred_rand))
print("Matriz de Confus√£o (RandomSearch):")
print(confusion_matrix(y_test, y_pred_rand))
print(f"Tempo de Infer√™ncia RandomSearch: {rand_time:.2f} segundos")
```

Essa an√°lise permite comparar os m√©todos de busca por hiperpar√¢metros, observando o impacto do ajuste fino no desempenho final e no tempo computacional necess√°rio. arquiteturas mais complexas.

Modelos como o Perceptron e MLP (Multilayer Perceptron) foram treinados usando bibliotecas como `scikit-learn`, al√©m de implementa√ß√µes manuais para entender o funcionamento interno dos pesos e gradientes. Analisamos tamb√©m a import√¢ncia da normaliza√ß√£o de entradas e da sele√ß√£o cuidadosa de hiperpar√¢metros.

Utilizamos dados reais de plataformas como o OpenML e aplicamos t√©cnicas de tuning, valida√ß√£o cruzada e grid search. Isso nos permitiu observar como pequenas mudan√ßas nos hiperpar√¢metros afetam drasticamente o desempenho do modelo.

Como exemplo pr√°tico adicional, exploramos um sinal de ECG utilizando a biblioteca TSFEL (Time Series Feature Extraction Library) para an√°lise explorat√≥ria de dados (EDA). Abaixo, temos um exemplo de carregamento e extra√ß√£o de atributos:

```python
import pandas as pd
from tsfel.feature_extraction import features
import tsfel

# Carregar o sinal ECG
from sklearn.model_selection import train_test_split
import openml

# Carregar dataset de ECG diretamente do OpenML
# Exemplo: dataset ID 44026 (ECG5000) dispon√≠vel em https://www.openml.org/d/44026
dataset = openml.datasets.get_dataset(44026)
df, *_ = dataset.get_data()

# Seleciona apenas a coluna do sinal e r√≥tulo
ecgs = df.iloc[:, :-1]  # Sinais
labels = df.iloc[:, -1]  # R√≥tulos

# Configura√ß√µes de extra√ß√£o do TSFEL
cfg = tsfel.get_features_by_domain()

# Extra√ß√£o autom√°tica dos atributos
X = tsfel.time_series_features_extractor(cfg, ecg)
print(X.head())
```

Esse procedimento transforma um sinal bruto em um vetor de atributos interpret√°veis, permitindo o uso de t√©cnicas de aprendizado supervisionado. O pr√≥ximo passo seria aplicar uma an√°lise de componentes principais (PCA) para reduzir a dimensionalidade e visualizar a distribui√ß√£o dos dados.

```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

plt.scatter(X_pca[:, 0], X_pca[:, 1])
plt.title("PCA dos atributos extra√≠dos do ECG")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()
```

Essa aplica√ß√£o mostra que mesmo sinais unidimensionais como o ECG podem ser tratados com redes neurais ap√≥s uma etapa eficiente de engenharia de atributos, refor√ßando a import√¢ncia do pr√©-processamento antes do uso de CNNs ou MLPs.

Durante o primeiro semestre, exploramos a base das redes neurais artificiais (RNA), abordando estruturas feedforward, algoritmos de retropropaga√ß√£o (backpropagation), fun√ß√µes de ativa√ß√£o, regulariza√ß√£o (L2, dropout, batch normalization) e otimizadores como SGD, Adam e RMSProp. A compreens√£o dessas estruturas √© essencial para avan√ßarmos para arquiteturas mais complexas.

Modelos como o Perceptron e MLP (Multilayer Perceptron) foram treinados usando bibliotecas como `scikit-learn`, al√©m de implementa√ß√µes manuais para entender o funcionamento interno dos pesos e gradientes. Analisamos tamb√©m a import√¢ncia da normaliza√ß√£o de entradas e da sele√ß√£o cuidadosa de hiperpar√¢metros.

Utilizamos dados reais de plataformas como o OpenML e aplicamos t√©cnicas de tuning, valida√ß√£o cruzada e grid search. Isso nos permitiu observar como pequenas mudan√ßas nos hiperpar√¢metros afetam drasticamente o desempenho do modelo.

Encerramos o semestre anterior com uma introdu√ß√£o ao ajuste de modelos, com destaque para a busca automatizada de hiperpar√¢metros. Agora, com essa base, podemos nos aprofundar nas redes convolucionais, que s√£o amplamente utilizadas para tarefas com imagens.

---

## üìò Parte 2 ‚Äì Teoria das Redes Convolucionais (CNNs)

As Redes Neurais Convolucionais (CNNs) s√£o uma classe especializada de redes projetadas para reconhecer padr√µes espaciais em dados com estrutura de grade, como imagens. Elas s√£o compostas por camadas convolucionais, camadas de pooling e camadas totalmente conectadas, que funcionam em conjunto para extrair e aprender representa√ß√µes hier√°rquicas de dados visuais.

A opera√ß√£o central das CNNs √© a convolu√ß√£o, em que um filtro (kernel) √© movido sobre a imagem de entrada para extrair padr√µes locais, como bordas, cantos e texturas. Essa abordagem permite o compartilhamento de pesos, reduzindo drasticamente a quantidade de par√¢metros em rela√ß√£o aos MLPs tradicionais. Segundo LeCun et al. (1998), essa arquitetura foi essencial para o sucesso do modelo LeNet-5 na classifica√ß√£o de d√≠gitos manuscritos \[1].

A camada de pooling (ou subamostragem) √© usada para reduzir a dimensionalidade espacial das representa√ß√µes intermedi√°rias. Isso n√£o apenas diminui o custo computacional, mas tamb√©m ajuda na generaliza√ß√£o, tornando o modelo menos sens√≠vel a pequenas mudan√ßas de posi√ß√£o. Dentre as t√©cnicas de pooling, o max pooling √© o mais utilizado.

[![Pooling](https://www.researchgate.net/publication/333593451/figure/fig2/AS:765890261966848@1559613876098/llustration-of-Max-Pooling-and-Average-Pooling-Figure-2-above-shows-an-example-of-max.png)](https://www.researchgate.net/publication/333593451/figure/fig2/AS:765890261966848@1559613876098/llustration-of-Max-Pooling-and-Average-Pooling-Figure-2-above-shows-an-example-of-max.png)

As CNNs tornaram-se o padr√£o de fato em tarefas como classifica√ß√£o de imagens (ImageNet), detec√ß√£o de objetos (YOLO, R-CNN) e reconhecimento facial. Seu desempenho superior √© sustentado por experimentos emp√≠ricos robustos, como demonstrado por Krizhevsky et al. (2012) no modelo AlexNet \[2].

![CNN nos D√≠gitos](https://www.louisbouchard.ai/content/images/size/w2000/2021/04/1_QPRC1lcfYxcWWPAC2hrQgg.gif)

Na pr√°tica, frameworks como TensorFlow, Keras e PyTorch facilitaram a constru√ß√£o e treinamento dessas redes, permitindo avan√ßos significativos em aplica√ß√µes de vis√£o computacional em tempo real, como carros aut√¥nomos e diagn√≥stico m√©dico por imagem \[3].



**Refer√™ncias:**
\[1] LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. *Proceedings of the IEEE*.
\[2] Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. *Advances in neural information processing systems*.
\[3] Litjens, G. et al. (2017). A survey on deep learning in medical image analysis. *Medical image analysis*, Elsevier.

---

## üíª Parte 3 ‚Äì Implementa√ß√£o de uma CNN com Keras

A seguir, realizamos a constru√ß√£o passo a passo de uma CNN simples utilizando a biblioteca Keras, com base no dataset MNIST. A cada linha de c√≥digo, explicaremos separadamente sua funcionalidade fora do bloco de c√≥digo, promovendo uma melhor compreens√£o did√°tica para os alunos.

```python
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
```

Importamos os m√≥dulos necess√°rios do Keras: `Sequential` para organizar o modelo em camadas sequenciais, e `Conv2D`, `MaxPooling2D`, `Flatten`, `Dense` que s√£o as camadas t√≠picas usadas em CNNs.

```python
model = Sequential()
```

Inicializamos o modelo sequencial. Isso significa que vamos adicionar as camadas uma ap√≥s a outra, formando uma pilha linear de camadas.

```python
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))
```

Adicionamos a primeira camada convolucional com 32 filtros de tamanho 3x3, ativa√ß√£o ReLU, e um formato de entrada de imagem 28x28 com 1 canal (tons de cinza).

```python
model.add(MaxPooling2D(pool_size=(2,2)))
```

Adicionamos uma camada de pooling com janelas de 2x2 para reduzir as dimens√µes espaciais pela metade, mantendo as informa√ß√µes mais relevantes.

```python
model.add(Flatten())
```

Transformamos a sa√≠da bidimensional das camadas anteriores em um vetor unidimensional, necess√°rio para conectar √†s camadas densas.

```python
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))
```

Adicionamos uma camada densa com 128 neur√¥nios e ativa√ß√£o ReLU, seguida por uma camada de sa√≠da com 10 neur√¥nios e ativa√ß√£o softmax para classifica√ß√£o multiclasse (0 a 9).

```python
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

Compilamos o modelo utilizando o otimizador Adam, fun√ß√£o de perda categorical crossentropy (adequada para classifica√ß√£o multiclasse) e m√©trica de acur√°cia.

---

## üß™ Atividade em Sala

**T√≠tulo:** Construindo uma CNN para classificar d√≠gitos manuscritos (MNIST)

### Instru√ß√µes:

1. Carregue o dataset MNIST via `keras.datasets`.
2. Normalize os dados e aplique one-hot encoding nas sa√≠das.
3. Use a estrutura de CNN apresentada para classificar os d√≠gitos.
4. Avalie a acur√°cia no conjunto de teste.

---

## üß† Desafio para Casa

**T√≠tulo:** Modificando a CNN com mais camadas

### Instru√ß√µes:

1. Adicione uma segunda camada convolucional e de pooling ao modelo apresentado.
2. Treine novamente e compare os resultados de acur√°cia com o modelo original.
3. Explique as diferen√ßas observadas em termos de generaliza√ß√£o e overfitting.

---

## ‚úÖ Conclus√£o

A introdu√ß√£o das CNNs marca um passo importante na disciplina, abrindo as portas para aplica√ß√µes em vis√£o computacional. A compreens√£o te√≥rica e pr√°tica dessa arquitetura nos prepara para redes mais profundas e especializadas que estudaremos ao longo do semestre.

# üß† Aula 10.1: Regulariza√ß√£o com Batch Normalization e Dropout

## üéØ Objetivo
Aprofundar os conhecimentos em regulariza√ß√£o, apresentando as t√©cnicas de **Batch Normalization** e **Dropout**, que ajudam a melhorar a estabilidade e a capacidade de generaliza√ß√£o de redes neurais.

---

## üìö Conte√∫do Program√°tico

### 1. Batch Normalization
- Normaliza as ativa√ß√µes de cada camada durante o treinamento.
- Ajuda a estabilizar o aprendizado e acelerar a converg√™ncia.
- Aplicada entre a multiplica√ß√£o de pesos e a fun√ß√£o de ativa√ß√£o.

### F√≥rmula:
\$$\hat{x}^{(k)} = \frac{x^{(k)} - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}\$$
- \$$\mu_B \$$: m√©dia do mini-batch
- \$$\sigma_B^2 \$$: vari√¢ncia do mini-batch

### Exemplo com Keras:
```python
from keras.models import Sequential
from keras.layers import Dense, BatchNormalization

model = Sequential()
model.add(Dense(64, input_shape=(X.shape[1],)))
model.add(BatchNormalization())
model.add(Dense(1, activation='sigmoid'))
```

---

### 2. Dropout
- Desativa aleatoriamente neur√¥nios durante o treinamento.
- Ajuda a evitar coadapta√ß√£o entre neur√¥nios.
- Estimula a rede a aprender representa√ß√µes mais robustas.

### Exemplo com Keras:
```python
from keras.layers import Dropout

model = Sequential()
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))
```

---

## ‚ö†Ô∏è Considera√ß√µes
- **Batch Normalization** e **Dropout** n√£o devem ser usados indiscriminadamente.
- Em alguns casos, podem competir entre si ou ser redundantes.
- Testar e validar diferentes combina√ß√µes √© essencial.

---

## üß™ Atividade em Sala

**T√≠tulo:** Testando as regulariza√ß√µes modernas

### Instru√ß√µes:
1. Escolha um dataset simples (ex: OpenML, Iris ou Breast Cancer).
2. Implemente um modelo com:
   - Apenas Batch Normalization
   - Apenas Dropout
   - Ambos combinados
3. Compare o desempenho de cada vers√£o.
4. Justifique qual combina√ß√£o apresentou melhor generaliza√ß√£o.

---

## üß† Desafio para Casa

**T√≠tulo:** Rede neural robusta para classifica√ß√£o

### Instru√ß√µes:
1. Escolha um dataset com pelo menos 3 classes e 200 amostras.
2. Implemente um modelo com camadas ocultas, Batch Normalization e Dropout.
3. Use valida√ß√£o cruzada para avaliar a robustez.
4. Crie gr√°ficos de compara√ß√£o.

---

## ‚úÖ Conclus√£o

Batch Normalization e Dropout s√£o t√©cnicas modernas de regulariza√ß√£o que, se bem aplicadas, tornam redes neurais mais est√°veis, eficientes e capazes de generalizar melhor em problemas reais.


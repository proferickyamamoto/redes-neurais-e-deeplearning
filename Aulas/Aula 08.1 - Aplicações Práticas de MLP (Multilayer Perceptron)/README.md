# ğŸ§  Aula 08.1: AplicaÃ§Ãµes PrÃ¡ticas de MLP (Multilayer Perceptron)

## ğŸ¯ Objetivo
Explorar **aplicaÃ§Ãµes reais** das redes neurais multicamadas (MLPs), reforÃ§ando os conceitos de aprendizado supervisionado e demonstrando como essas arquiteturas podem resolver problemas complexos de classificaÃ§Ã£o e regressÃ£o.

---

## ğŸ“š ConteÃºdo ProgramÃ¡tico

### 1. O que Ã© uma MLP?
- Rede neural com pelo menos **uma camada oculta**.
- Cada camada Ã© composta por neurÃ´nios com funÃ§Ãµes de ativaÃ§Ã£o (ex: ReLU, sigmoide).
- Aprendizado via **backpropagation**.

### 2. Exemplos de AplicaÃ§Ã£o
- ClassificaÃ§Ã£o de padrÃµes (ex: letras manuscritas, reconhecimento facial)
- DiagnÃ³stico mÃ©dico
- PrevisÃ£o de sÃ©ries temporais (ex: temperatura, vendas)
- Reconhecimento de voz

---

## ğŸ—ï¸ Estrutura TÃ­pica de uma MLP

```
Entrada â†’ Camada Oculta (n neurÃ´nios) â†’ Camada de SaÃ­da
```

- FunÃ§Ã£o de ativaÃ§Ã£o recomendada para a camada oculta: `ReLU`
- FunÃ§Ã£o para a saÃ­da:
  - **FunÃ§Ãµes de ativaÃ§Ã£o recomendadas para a saÃ­da:**

- `Sigmoid`: usada em **classificaÃ§Ãµes binÃ¡rias**. Produz uma saÃ­da entre 0 e 1, interpretÃ¡vel como probabilidade.
  ![Sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)

- `Softmax`: usada em **classificaÃ§Ãµes multiclasse**. Normaliza as saÃ­das em um vetor de probabilidades que somam 1.
  ![Softmax example](https://upload.wikimedia.org/wikipedia/commons/8/8a/Softmax_function.svg)

- `Linear`: usada em **regressÃ£o**, ou seja, problemas com saÃ­da numÃ©rica contÃ­nua. A saÃ­da Ã© diretamente proporcional Ã  soma ponderada das ativaÃ§Ãµes.
  ![Linear function](https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_function.svg)

---

## ğŸ’» Exemplo PrÃ¡tico: ClassificaÃ§Ã£o de Flores (Iris Dataset)

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

# Carregar dados
iris = load_iris()
X = iris.data
y = iris.target

# PrÃ©-processamento
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir treino/teste
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Criar modelo MLP
mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)
mlp.fit(X_train, y_train)

# AvaliaÃ§Ã£o
y_pred = mlp.predict(X_test)
print("AcurÃ¡cia:", accuracy_score(y_test, y_pred))
```

### Resultado esperado:
> AcurÃ¡cia acima de 90% para classificaÃ§Ã£o das espÃ©cies de flores.

---

## ğŸ§ª Atividade em Sala

**TÃ­tulo:** Classificando pacientes com MLP

### InstruÃ§Ãµes:
1. Criar um dataset com variÃ¡veis como: febre, tosse, dor de cabeÃ§a (0 ou 1).
2. Rotular os dados como â€œdoenteâ€ (1) ou â€œsaudÃ¡velâ€ (0).
3. Utilizar `MLPClassifier` para treinar um modelo.
4. Avaliar a acurÃ¡cia do modelo com dados de teste.

**Desafio extra:** Testar diferentes quantidades de neurÃ´nios na camada oculta e comparar os resultados.

---

## ğŸ§  Desafio para Casa

**TÃ­tulo:** PrevisÃ£o de Vendas com MLPRegressor

### Objetivo:
Usar uma rede neural para prever o valor de vendas futuras com base em entradas como mÃªs, promoÃ§Ãµes, clima.

### InstruÃ§Ãµes:
1. Criar um pequeno dataset fictÃ­cio com entradas contÃ­nuas.
2. Utilizar `MLPRegressor` do `sklearn.neural_network`.
3. Avaliar o erro com `mean_squared_error`.

---

## âœ… ConclusÃ£o

Redes do tipo **MLP** sÃ£o extremamente versÃ¡teis e aplicÃ¡veis em diversas Ã¡reas. Ao entender como ajustar hiperparÃ¢metros e interpretar os resultados, os alunos podem aplicar essas redes com confianÃ§a em problemas reais.

